{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cea12ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6df49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4\n",
    "z_dim = 784\n",
    "image_dim = 28 * 28 * 1  # 784\n",
    "batch_size = 32\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fea87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset module\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    '''\n",
    "    downloads MNIST dataset, performs splitting and transformation, and returns dataloaders\n",
    "    '''\n",
    "    def __init__(self, root = './data', download = True, transform = None):\n",
    "        # download mnist dataset\n",
    "        self.mnist = MNIST(root = root, download = download)\n",
    "\n",
    "        # default transformation if no specific transformation is provided\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "        self.indices = list(range(len(self.mnist)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.mnist[self.indices[idx]]\n",
    "    \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def get_dataloader(self, batch_size = batch_size, shuffle = True):\n",
    "        return DataLoader(self, batch_size = batch_size, shuffle = shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c74f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTDataset()\n",
    "train_dataloader = train_dataset.get_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55e9aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels = 1):\n",
    "        super().__init__()\n",
    "        # Simple CNN\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=4, stride = 2, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride = 2, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc = nn.Linear(256 * 3 * 3, 1)\n",
    "\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace = True)\n",
    "        x = F.leaky_relu(self.bn1(self.conv2(x)), 0.2, inplace = True)\n",
    "        x = F.leaky_relu(self.bn2(self.conv3(x)), 0.2, inplace = True)\n",
    "        # Flatten the tensor so it can be fed into the FC layers\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ece90350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generates new images from random noise\n",
    "    in: latent_dim 256*7*7\n",
    "    out: 28x28\n",
    "    '''\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "        nn.Linear(z_dim, 7*7*64),\n",
    "        nn.ReLU(),\n",
    "        nn.Unflatten(1, (64, 7, 7)),\n",
    "        nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2),  # 1x1 → 7x7\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2),  # 7x7 → 14x14\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size = 7)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(self.gen(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator().to(device)\n",
    "gen = Generator(z_dim).to(device)\n",
    "\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real) in enumerate(tqdm(train_dataloader)):\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        # where the second option of maximizing doesn't suffer from\n",
    "        # saturating gradients\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(train_dataloader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                data = real\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference block"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
